{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexmVsrYsvPr"
      },
      "source": [
        "# Check for Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmhOcAQSsDEr",
        "outputId": "07b5afda-f656-4721-a3f5-78ceade04769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import IPython\n",
        "print('IPython:', IPython.__version__)\n",
        "\n",
        "import pkg_resources\n",
        "for pkg in ['numpy', 'matplotlib', 'torch', 'torchvision']:\n",
        "    print(pkg + ':', pkg_resources.get_distribution(pkg).version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IPython: 5.5.0\n",
            "numpy: 1.16.4\n",
            "matplotlib: 3.0.3\n",
            "torch: 1.1.0\n",
            "torchvision: 0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMX0inTjttPj"
      },
      "source": [
        "# Problem Background\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "Here's an example how the data looks (each class takes three-rows):\n",
        "![alt_text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
        "\n",
        "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
        "\n",
        "(taken from [here](https://github.com/zalandoresearch/fashion-mnist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFPFQJcYuoGu"
      },
      "source": [
        "# Data Description\n",
        "\n",
        "| Label | Description |\n",
        "| :---: | ----- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnya8N4xi72e"
      },
      "source": [
        "# Benchmarking\n",
        "These are the current reported 3 best classification results, taken from the same link as above.\n",
        "\n",
        "| Classifier | Preprocessing | Test Accuracy |\n",
        "| ----- | ----- | :---: |\n",
        "| [WRN40-4 8.9M params](https://github.com/ajbrock/FreezeOut) | standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.967 |\n",
        "| [WRN-28-10 + Random Erasing](https://github.com/zhunzhong07/Random-Erasing) | standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.963 |\n",
        "| [WRN-28-10](https://github.com/zhunzhong07/Random-Erasing)\t| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.959 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nClabwUj30Tu"
      },
      "source": [
        "# Load the Data\n",
        "The Fashion-MNIST dataset is available in torchvision. The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiynrjux2-cx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math, random, copy\n",
        "from collections import *\n",
        "from time import time\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "from torchvision import utils, models, transforms\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnYA-3CAAOP4"
      },
      "source": [
        "np.random.seed(123);\n",
        "random.seed(123);\n",
        "torch.manual_seed(123);\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX9Qh0Ps2-Zq"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = FashionMNIST(root = './data', train = True, download = True, transform = transform)\n",
        "trainloader = DataLoader(trainset, batch_size = 32, shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = FashionMNIST(root = './data', train = False, download = True, transform = transform)\n",
        "testloader = DataLoader(testset, batch_size = 32, shuffle = False, num_workers = 2)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
        "labeldict = dict(zip(range(10), classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ALlqfrl_KT-",
        "outputId": "1191ef9d-2b6b-4f96-acc3-595ecca6ffe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "source": [
        "def imshow(inp, title = None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.01)  # pause a bit so that plots are updated\n",
        "\n",
        "# Get some training data\n",
        "example_data = random.sample(range(60000), 4)\n",
        "images, labels = [trainset[i][0] for i in example_data], [trainset[i][1] for i in example_data]\n",
        "\n",
        "# Make a grid from the example datas\n",
        "out = utils.make_grid(images)\n",
        "\n",
        "imshow(out, title = [labeldict[x] for x in labels])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAACHCAYAAAAC53JtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8aDO5Va0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O49EIUMSteCo"
      },
      "source": [
        "# Define Model Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2eHkfi5tdt6"
      },
      "source": [
        "dataloaders = {'train': trainloader,\n",
        "               'val'  : testloader}\n",
        "dataset_sizes = {'train': len(trainset),\n",
        "                 'val'  : len(testset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXKQYYf_tdf2"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n",
        "    start = time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        to_print = 'Epoch {}: '.format(str(' ' if epoch < 9 else '') + str(epoch + 1) + '/' + str(num_epochs))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                to_print += ', '\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            to_print += '{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print(to_print)\n",
        "\n",
        "    time_elapsed = time() - start\n",
        "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj8lyjyvCb3c"
      },
      "source": [
        "# Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFD7HKcRFUiD",
        "outputId": "db0b8d6f-3202-4de2-e64e-bf9ce0b6a19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10),\n",
        "            nn.LogSoftmax(dim = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = input_tensor.view(-1, 28*28)\n",
        "        return self.model(x)\n",
        "\n",
        "print(MLP())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "    (5): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenAOs6mAtij"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdtxmBPuByOt",
        "outputId": "482deedd-fd87-4889-9210-91292d2e5125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size = 5, padding = 2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size = 5, padding = 2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Linear(7*7*32, 10)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = self.layer1(input_tensor)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "print(CNN())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyhtFa2MI0tI"
      },
      "source": [
        "# Torchvision Models\n",
        "The following models are taken from predefined model architectures in the Torchvision package called from [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html). However these models take in an input of RGB hex coloring, therefore 3 channels. All we need to do is to take the source codes for these predefined models and tweak the models to take in an input of grayscale coloring, which is 1 channel. This is the only necessary tweak and we'll leave the rest of the source code as is.\n",
        "\n",
        "We will explore these models:\n",
        "* AlexNet\n",
        "* VGG\n",
        "* ResNet\n",
        "* SqueezeNet\n",
        "* DenseNet\n",
        "* **Inception v3**\n",
        "* **GoogLeNet**\n",
        "* **ShuffleNet v2**\n",
        "* MobileNet v2\n",
        "* ResNeXt\n",
        "* **WideResNet**\n",
        "\n",
        "and measure their performance, starting with VGG16, ResNet 18, ResNet 50, and ResNet 152. The models in bold will be checked out in a different section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GtU2RtfI0XH",
        "outputId": "906a2e34-9eb2-440e-e679-a0f273f2a830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "nets = np.array([model for model in dir(models) if model[0] != '_'])\n",
        "nets = np.setdiff1d(nets, 'utils')\n",
        "nets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AlexNet', 'DenseNet', 'GoogLeNet', 'Inception3', 'MobileNetV2',\n",
              "       'ResNet', 'ShuffleNetV2', 'SqueezeNet', 'VGG', 'alexnet',\n",
              "       'densenet', 'densenet121', 'densenet161', 'densenet169',\n",
              "       'densenet201', 'detection', 'googlenet', 'inception',\n",
              "       'inception_v3', 'mobilenet', 'mobilenet_v2', 'resnet', 'resnet101',\n",
              "       'resnet152', 'resnet18', 'resnet34', 'resnet50',\n",
              "       'resnext101_32x8d', 'resnext50_32x4d', 'segmentation',\n",
              "       'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5',\n",
              "       'shufflenet_v2_x2_0', 'shufflenetv2', 'squeezenet',\n",
              "       'squeezenet1_0', 'squeezenet1_1', 'vgg', 'vgg11', 'vgg11_bn',\n",
              "       'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn'],\n",
              "      dtype='<U18')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDnGvGIk-Txy"
      },
      "source": [
        "## VGG\n",
        "See [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhEjAWMx-TSv"
      },
      "source": [
        "model_urls = {\n",
        "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
        "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
        "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
        "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
        "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
        "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, num_classes = 10, init_weights = True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512*7*7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 1\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "cfgs = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def _vgg(arch, cfg, batch_norm, pretrained, progress, **kwargs):\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def vgg16(pretrained = False, progress=True, **kwargs):\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ml3wukI-EOO"
      },
      "source": [
        "## ResNet\n",
        "See [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyt5J_D0IE4r"
      },
      "source": [
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def _resnet(arch, inplanes, planes, pretrained, progress, **kwargs):\n",
        "    model = ResNet(inplanes, planes, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "def resnet50(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "def resnet152(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
        "                   **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1BDUNm-uTK"
      },
      "source": [
        "## AlexNet\n",
        "See [One weird trick for parallelizing convolutional neural networks](https://arxiv.org/abs/1404.5997)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGPbhHRQ-LFm"
      },
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256*6*6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-esDZUI-3bg"
      },
      "source": [
        "## SqueezeNet\n",
        "See [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujrC8GvW-5mn"
      },
      "source": [
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "class Fire(nn.Module):\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "    def __init__(self, version='1_0', num_classes=10):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        if version == '1_0':\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(1, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        elif version == '1_1':\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(1, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            # FIXME: Is this needed? SqueezeNet should only be called from the\n",
        "            # FIXME: squeezenet1_x() functions\n",
        "            # FIXME: This checking is not done for the other models\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1_0 or 1_1 expected\".format(version=version))\n",
        "\n",
        "        # Final convolution is initialized differently from the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "def _squeezenet(version, pretrained, progress, **kwargs):\n",
        "    model = SqueezeNet(version, **kwargs)\n",
        "    if pretrained:\n",
        "        arch = 'squeezenet' + version\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def squeezenet1_0(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _squeezenet('1_0', pretrained, progress, **kwargs)\n",
        "\n",
        "def squeezenet1_1(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _squeezenet('1_1', pretrained, progress, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ummm4azu-0Vb"
      },
      "source": [
        "## DenseNet\n",
        "See [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjZH15qi-LC6"
      },
      "source": [
        "model_urls = {\n",
        "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
        "}\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate,\n",
        "                                bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    \"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate,\n",
        "                                drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1)).view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "def _load_state_dict(model, model_url, progress):\n",
        "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
        "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "    # They are also in the checkpoints in model_urls. This pattern is used\n",
        "    # to find such keys.\n",
        "    pattern = re.compile(\n",
        "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "\n",
        "    state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
        "    for key in list(state_dict.keys()):\n",
        "        res = pattern.match(key)\n",
        "        if res:\n",
        "            new_key = res.group(1) + res.group(2)\n",
        "            state_dict[new_key] = state_dict[key]\n",
        "            del state_dict[key]\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n",
        "              **kwargs):\n",
        "    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n",
        "    if pretrained:\n",
        "        _load_state_dict(model, model_urls[arch], progress)\n",
        "    return model\n",
        "\n",
        "def densenet121(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "def densenet161(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "def densenet201(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n",
        "                     **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpKrVTIvCr_G"
      },
      "source": [
        "## MobileNet\n",
        "See [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pyEp0aVCsZc"
      },
      "source": [
        "model_urls = {\n",
        "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            nn.BatchNorm2d(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(oup),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=1000, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "        \"\"\"\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 2],\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 96, 3, 1],\n",
        "                [6, 160, 3, 2],\n",
        "                [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean([2, 3])\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a MobileNetV2 architecture from\n",
        "    `\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" <https://arxiv.org/abs/1801.04381>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZSMe24wDAG1"
      },
      "source": [
        "## ResNeXt\n",
        "See [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og0J_Sc0DAfG"
      },
      "source": [
        "def resnext50_32x4d(**kwargs):\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 4\n",
        "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
        "                   pretrained=False, progress=True, **kwargs)\n",
        "\n",
        "def resnext101_32x8d(**kwargs):\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 8\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained=False, progress=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IGhkoDC2ct_"
      },
      "source": [
        "# Baseline Training and Evaluation\n",
        "For baselining purposes, we have used the basic transformers ToTensor and Normalization(0.5). We will now also use the same optimization being SGD with lr = 0.001 and momentum = 0.9 with the same Step LR Scheduler with step_size = 7, gamma = 0.1 with the same 25 epochs. The result of this baselining will be further examined in the preceding sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVTVNtlbB9oL"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja3J95aormnH",
        "outputId": "46912c4a-e4a0-4085-809a-ca59b5def6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "mlp = MLP().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(mlp.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "mlp_model = train_model(mlp, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.8266 Acc: 0.7195, val Loss: 0.5563 Acc: 0.7993\n",
            "Epoch  2/25: train Loss: 0.4885 Acc: 0.8225, val Loss: 0.4849 Acc: 0.8258\n",
            "Epoch  3/25: train Loss: 0.4346 Acc: 0.8424, val Loss: 0.4530 Acc: 0.8396\n",
            "Epoch  4/25: train Loss: 0.4041 Acc: 0.8543, val Loss: 0.4234 Acc: 0.8478\n",
            "Epoch  5/25: train Loss: 0.3823 Acc: 0.8627, val Loss: 0.4206 Acc: 0.8508\n",
            "Epoch  6/25: train Loss: 0.3651 Acc: 0.8684, val Loss: 0.3946 Acc: 0.8573\n",
            "Epoch  7/25: train Loss: 0.3383 Acc: 0.8800, val Loss: 0.3862 Acc: 0.8618\n",
            "Epoch  8/25: train Loss: 0.3357 Acc: 0.8813, val Loss: 0.3839 Acc: 0.8631\n",
            "Epoch  9/25: train Loss: 0.3337 Acc: 0.8815, val Loss: 0.3829 Acc: 0.8638\n",
            "Epoch 10/25: train Loss: 0.3321 Acc: 0.8819, val Loss: 0.3822 Acc: 0.8641\n",
            "Epoch 11/25: train Loss: 0.3304 Acc: 0.8827, val Loss: 0.3810 Acc: 0.8642\n",
            "Epoch 12/25: train Loss: 0.3287 Acc: 0.8835, val Loss: 0.3793 Acc: 0.8657\n",
            "Epoch 13/25: train Loss: 0.3272 Acc: 0.8835, val Loss: 0.3779 Acc: 0.8648\n",
            "Epoch 14/25: train Loss: 0.3245 Acc: 0.8846, val Loss: 0.3775 Acc: 0.8654\n",
            "Epoch 15/25: train Loss: 0.3242 Acc: 0.8848, val Loss: 0.3773 Acc: 0.8654\n",
            "Epoch 16/25: train Loss: 0.3240 Acc: 0.8848, val Loss: 0.3771 Acc: 0.8658\n",
            "Epoch 17/25: train Loss: 0.3238 Acc: 0.8850, val Loss: 0.3772 Acc: 0.8657\n",
            "Epoch 18/25: train Loss: 0.3237 Acc: 0.8848, val Loss: 0.3769 Acc: 0.8660\n",
            "Epoch 19/25: train Loss: 0.3235 Acc: 0.8852, val Loss: 0.3770 Acc: 0.8657\n",
            "Epoch 20/25: train Loss: 0.3233 Acc: 0.8853, val Loss: 0.3768 Acc: 0.8661\n",
            "Epoch 21/25: train Loss: 0.3230 Acc: 0.8849, val Loss: 0.3767 Acc: 0.8661\n",
            "Epoch 22/25: train Loss: 0.3230 Acc: 0.8851, val Loss: 0.3767 Acc: 0.8660\n",
            "Epoch 23/25: train Loss: 0.3230 Acc: 0.8851, val Loss: 0.3767 Acc: 0.8659\n",
            "Epoch 24/25: train Loss: 0.3229 Acc: 0.8853, val Loss: 0.3767 Acc: 0.8658\n",
            "Epoch 25/25: train Loss: 0.3229 Acc: 0.8852, val Loss: 0.3767 Acc: 0.8660\n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val Acc: 0.8661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X7fZnkNrmce",
        "outputId": "b73ae45c-d06e-4bf0-ba16-58ffe7ecacc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "cnn = CNN().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(cnn.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "cnn_model = train_model(cnn, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4912 Acc: 0.8299, val Loss: 0.3751 Acc: 0.8678\n",
            "Epoch  2/25: train Loss: 0.3313 Acc: 0.8824, val Loss: 0.3308 Acc: 0.8804\n",
            "Epoch  3/25: train Loss: 0.2946 Acc: 0.8959, val Loss: 0.3200 Acc: 0.8862\n",
            "Epoch  4/25: train Loss: 0.2742 Acc: 0.9023, val Loss: 0.3040 Acc: 0.8920\n",
            "Epoch  5/25: train Loss: 0.2584 Acc: 0.9081, val Loss: 0.3084 Acc: 0.8880\n",
            "Epoch  6/25: train Loss: 0.2452 Acc: 0.9123, val Loss: 0.3127 Acc: 0.8879\n",
            "Epoch  7/25: train Loss: 0.2142 Acc: 0.9249, val Loss: 0.2742 Acc: 0.9014\n",
            "Epoch  8/25: train Loss: 0.2095 Acc: 0.9270, val Loss: 0.2722 Acc: 0.9034\n",
            "Epoch  9/25: train Loss: 0.2076 Acc: 0.9287, val Loss: 0.2719 Acc: 0.9031\n",
            "Epoch 10/25: train Loss: 0.2059 Acc: 0.9280, val Loss: 0.2707 Acc: 0.9031\n",
            "Epoch 11/25: train Loss: 0.2047 Acc: 0.9292, val Loss: 0.2703 Acc: 0.9039\n",
            "Epoch 12/25: train Loss: 0.2025 Acc: 0.9299, val Loss: 0.2695 Acc: 0.9029\n",
            "Epoch 13/25: train Loss: 0.2013 Acc: 0.9300, val Loss: 0.2685 Acc: 0.9042\n",
            "Epoch 14/25: train Loss: 0.1975 Acc: 0.9321, val Loss: 0.2688 Acc: 0.9040\n",
            "Epoch 15/25: train Loss: 0.1972 Acc: 0.9322, val Loss: 0.2685 Acc: 0.9039\n",
            "Epoch 16/25: train Loss: 0.1966 Acc: 0.9324, val Loss: 0.2683 Acc: 0.9039\n",
            "Epoch 17/25: train Loss: 0.1964 Acc: 0.9327, val Loss: 0.2686 Acc: 0.9046\n",
            "Epoch 18/25: train Loss: 0.1967 Acc: 0.9323, val Loss: 0.2682 Acc: 0.9046\n",
            "Epoch 19/25: train Loss: 0.1966 Acc: 0.9327, val Loss: 0.2682 Acc: 0.9051\n",
            "Epoch 20/25: train Loss: 0.1962 Acc: 0.9327, val Loss: 0.2684 Acc: 0.9052\n",
            "Epoch 21/25: train Loss: 0.1955 Acc: 0.9328, val Loss: 0.2685 Acc: 0.9042\n",
            "Epoch 22/25: train Loss: 0.1957 Acc: 0.9326, val Loss: 0.2682 Acc: 0.9051\n",
            "Epoch 23/25: train Loss: 0.1958 Acc: 0.9324, val Loss: 0.2686 Acc: 0.9050\n",
            "Epoch 24/25: train Loss: 0.1955 Acc: 0.9330, val Loss: 0.2684 Acc: 0.9045\n",
            "Epoch 25/25: train Loss: 0.1955 Acc: 0.9329, val Loss: 0.2681 Acc: 0.9048\n",
            "\n",
            "Training complete in 5m 36s\n",
            "Best val Acc: 0.9052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq26wBOCrmZC",
        "outputId": "5358d29f-6815-4df4-aab3-319a1daf7a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "VGG16 = vgg16().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(VGG16.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "VGG16_model = train_model(VGG16, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 2.2993 Acc: 0.1452, val Loss: 2.2796 Acc: 0.2680\n",
            "Epoch  2/25: train Loss: 1.0716 Acc: 0.5902, val Loss: 0.5644 Acc: 0.7849\n",
            "Epoch  3/25: train Loss: 0.4907 Acc: 0.8154, val Loss: 0.4185 Acc: 0.8492\n",
            "Epoch  4/25: train Loss: 0.3803 Acc: 0.8625, val Loss: 0.3641 Acc: 0.8694\n",
            "Epoch  5/25: train Loss: 0.3226 Acc: 0.8827, val Loss: 0.3317 Acc: 0.8810\n",
            "Epoch  6/25: train Loss: 0.2866 Acc: 0.8963, val Loss: 0.2903 Acc: 0.8932\n",
            "Epoch  7/25: train Loss: 0.2206 Acc: 0.9197, val Loss: 0.2688 Acc: 0.9023\n",
            "Epoch  8/25: train Loss: 0.2064 Acc: 0.9256, val Loss: 0.2650 Acc: 0.9082\n",
            "Epoch  9/25: train Loss: 0.1966 Acc: 0.9289, val Loss: 0.2606 Acc: 0.9084\n",
            "Epoch 10/25: train Loss: 0.1888 Acc: 0.9326, val Loss: 0.2602 Acc: 0.9106\n",
            "Epoch 11/25: train Loss: 0.1793 Acc: 0.9361, val Loss: 0.2552 Acc: 0.9130\n",
            "Epoch 12/25: train Loss: 0.1716 Acc: 0.9385, val Loss: 0.2564 Acc: 0.9130\n",
            "Epoch 13/25: train Loss: 0.1633 Acc: 0.9430, val Loss: 0.2581 Acc: 0.9126\n",
            "Epoch 14/25: train Loss: 0.1474 Acc: 0.9484, val Loss: 0.2552 Acc: 0.9155\n",
            "Epoch 15/25: train Loss: 0.1441 Acc: 0.9507, val Loss: 0.2565 Acc: 0.9153\n",
            "Epoch 16/25: train Loss: 0.1428 Acc: 0.9519, val Loss: 0.2563 Acc: 0.9154\n",
            "Epoch 17/25: train Loss: 0.1409 Acc: 0.9520, val Loss: 0.2567 Acc: 0.9157\n",
            "Epoch 18/25: train Loss: 0.1395 Acc: 0.9526, val Loss: 0.2567 Acc: 0.9150\n",
            "Epoch 19/25: train Loss: 0.1386 Acc: 0.9531, val Loss: 0.2571 Acc: 0.9151\n",
            "Epoch 20/25: train Loss: 0.1363 Acc: 0.9534, val Loss: 0.2609 Acc: 0.9138\n",
            "Epoch 21/25: train Loss: 0.1356 Acc: 0.9541, val Loss: 0.2584 Acc: 0.9157\n",
            "Epoch 22/25: train Loss: 0.1345 Acc: 0.9540, val Loss: 0.2582 Acc: 0.9157\n",
            "Epoch 23/25: train Loss: 0.1346 Acc: 0.9543, val Loss: 0.2583 Acc: 0.9159\n",
            "Epoch 24/25: train Loss: 0.1338 Acc: 0.9537, val Loss: 0.2581 Acc: 0.9152\n",
            "Epoch 25/25: train Loss: 0.1346 Acc: 0.9543, val Loss: 0.2581 Acc: 0.9153\n",
            "\n",
            "Training complete in 46m 13s\n",
            "Best val Acc: 0.9159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9-Q5nvFrmUW",
        "outputId": "d81e1968-5d9c-4b57-f550-2cecb743fa1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "ResNet18 = resnet18().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNet18.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNet18_model = train_model(ResNet18, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4684 Acc: 0.8287, val Loss: 0.3448 Acc: 0.8730\n",
            "Epoch  2/25: train Loss: 0.3190 Acc: 0.8814, val Loss: 0.3115 Acc: 0.8855\n",
            "Epoch  3/25: train Loss: 0.2689 Acc: 0.9001, val Loss: 0.2919 Acc: 0.8922\n",
            "Epoch  4/25: train Loss: 0.2367 Acc: 0.9104, val Loss: 0.3008 Acc: 0.8904\n",
            "Epoch  5/25: train Loss: 0.2098 Acc: 0.9209, val Loss: 0.2834 Acc: 0.9003\n",
            "Epoch  6/25: train Loss: 0.1908 Acc: 0.9281, val Loss: 0.2863 Acc: 0.8997\n",
            "Epoch  7/25: train Loss: 0.1314 Acc: 0.9516, val Loss: 0.2529 Acc: 0.9119\n",
            "Epoch  8/25: train Loss: 0.1128 Acc: 0.9590, val Loss: 0.2558 Acc: 0.9143\n",
            "Epoch  9/25: train Loss: 0.1016 Acc: 0.9629, val Loss: 0.2622 Acc: 0.9120\n",
            "Epoch 10/25: train Loss: 0.0939 Acc: 0.9659, val Loss: 0.2644 Acc: 0.9129\n",
            "Epoch 11/25: train Loss: 0.0869 Acc: 0.9689, val Loss: 0.2730 Acc: 0.9129\n",
            "Epoch 12/25: train Loss: 0.0800 Acc: 0.9709, val Loss: 0.2768 Acc: 0.9134\n",
            "Epoch 13/25: train Loss: 0.0737 Acc: 0.9742, val Loss: 0.2813 Acc: 0.9126\n",
            "Epoch 14/25: train Loss: 0.0634 Acc: 0.9795, val Loss: 0.2803 Acc: 0.9134\n",
            "Epoch 15/25: train Loss: 0.0631 Acc: 0.9785, val Loss: 0.2822 Acc: 0.9131\n",
            "Epoch 16/25: train Loss: 0.0625 Acc: 0.9788, val Loss: 0.2837 Acc: 0.9146\n",
            "Epoch 17/25: train Loss: 0.0611 Acc: 0.9798, val Loss: 0.2828 Acc: 0.9148\n",
            "Epoch 18/25: train Loss: 0.0601 Acc: 0.9803, val Loss: 0.2837 Acc: 0.9145\n",
            "Epoch 19/25: train Loss: 0.0594 Acc: 0.9804, val Loss: 0.2848 Acc: 0.9156\n",
            "Epoch 20/25: train Loss: 0.0591 Acc: 0.9803, val Loss: 0.2880 Acc: 0.9136\n",
            "Epoch 21/25: train Loss: 0.0569 Acc: 0.9816, val Loss: 0.2849 Acc: 0.9140\n",
            "Epoch 22/25: train Loss: 0.0582 Acc: 0.9813, val Loss: 0.2846 Acc: 0.9136\n",
            "Epoch 23/25: train Loss: 0.0575 Acc: 0.9814, val Loss: 0.2853 Acc: 0.9145\n",
            "Epoch 24/25: train Loss: 0.0573 Acc: 0.9815, val Loss: 0.2830 Acc: 0.9147\n",
            "Epoch 25/25: train Loss: 0.0569 Acc: 0.9816, val Loss: 0.2869 Acc: 0.9138\n",
            "\n",
            "Training complete in 19m 35s\n",
            "Best val Acc: 0.9156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq8tSV3WrmSJ",
        "outputId": "54ab7e49-3f0c-4349-d686-37e2f14a5204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "ResNet50 = resnet50().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNet50.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNet50_model = train_model(ResNet50, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.7584 Acc: 0.7361, val Loss: 0.4804 Acc: 0.8219\n",
            "Epoch  2/25: train Loss: 0.4572 Acc: 0.8342, val Loss: 0.4384 Acc: 0.8411\n",
            "Epoch  3/25: train Loss: 0.3720 Acc: 0.8621, val Loss: 0.3678 Acc: 0.8637\n",
            "Epoch  4/25: train Loss: 0.3186 Acc: 0.8825, val Loss: 0.3562 Acc: 0.8697\n",
            "Epoch  5/25: train Loss: 0.2904 Acc: 0.8912, val Loss: 0.3259 Acc: 0.8766\n",
            "Epoch  6/25: train Loss: 0.2638 Acc: 0.9010, val Loss: 0.3771 Acc: 0.8643\n",
            "Epoch  7/25: train Loss: 0.2016 Acc: 0.9244, val Loss: 0.2906 Acc: 0.8960\n",
            "Epoch  8/25: train Loss: 0.1817 Acc: 0.9324, val Loss: 0.2879 Acc: 0.8987\n",
            "Epoch  9/25: train Loss: 0.1717 Acc: 0.9353, val Loss: 0.2875 Acc: 0.8981\n",
            "Epoch 10/25: train Loss: 0.1614 Acc: 0.9396, val Loss: 0.2952 Acc: 0.8980\n",
            "Epoch 11/25: train Loss: 0.1542 Acc: 0.9426, val Loss: 0.2926 Acc: 0.8983\n",
            "Epoch 12/25: train Loss: 0.1457 Acc: 0.9456, val Loss: 0.3011 Acc: 0.8973\n",
            "Epoch 13/25: train Loss: 0.1384 Acc: 0.9485, val Loss: 0.3036 Acc: 0.8978\n",
            "Epoch 14/25: train Loss: 0.1258 Acc: 0.9538, val Loss: 0.3057 Acc: 0.9006\n",
            "Epoch 15/25: train Loss: 0.1245 Acc: 0.9539, val Loss: 0.3029 Acc: 0.8988\n",
            "Epoch 16/25: train Loss: 0.1238 Acc: 0.9541, val Loss: 0.3067 Acc: 0.8993\n",
            "Epoch 17/25: train Loss: 0.1217 Acc: 0.9546, val Loss: 0.3040 Acc: 0.8996\n",
            "Epoch 18/25: train Loss: 0.1204 Acc: 0.9557, val Loss: 0.3068 Acc: 0.9001\n",
            "Epoch 19/25: train Loss: 0.1190 Acc: 0.9568, val Loss: 0.3055 Acc: 0.9004\n",
            "Epoch 20/25: train Loss: 0.1186 Acc: 0.9567, val Loss: 0.3095 Acc: 0.9013\n",
            "Epoch 21/25: train Loss: 0.1165 Acc: 0.9579, val Loss: 0.3088 Acc: 0.8997\n",
            "Epoch 22/25: train Loss: 0.1173 Acc: 0.9571, val Loss: 0.3061 Acc: 0.8998\n",
            "Epoch 23/25: train Loss: 0.1158 Acc: 0.9575, val Loss: 0.3083 Acc: 0.8994\n",
            "Epoch 24/25: train Loss: 0.1174 Acc: 0.9564, val Loss: 0.3062 Acc: 0.8996\n",
            "Epoch 25/25: train Loss: 0.1181 Acc: 0.9567, val Loss: 0.3107 Acc: 0.8991\n",
            "\n",
            "Training complete in 124m 22s\n",
            "Best val Acc: 0.9013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQZhnv9rmBs",
        "outputId": "3922c780-1f0c-4157-ffde-35b445361a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "ResNet152 = resnet152().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNet152.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNet152_model = train_model(ResNet152, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.9888 Acc: 0.6590, val Loss: 0.6916 Acc: 0.7677\n",
            "Epoch  2/25: train Loss: 0.6040 Acc: 0.7810, val Loss: 0.5207 Acc: 0.8136\n",
            "Epoch  3/25: train Loss: 0.5090 Acc: 0.8115, val Loss: 0.4681 Acc: 0.8224\n",
            "Epoch  4/25: train Loss: 0.4503 Acc: 0.8337, val Loss: 0.5060 Acc: 0.8264\n",
            "Epoch  5/25: train Loss: 0.4120 Acc: 0.8464, val Loss: 0.4223 Acc: 0.8504\n",
            "Epoch  6/25: train Loss: 0.3792 Acc: 0.8585, val Loss: 0.4421 Acc: 0.8516\n",
            "Epoch  7/25: train Loss: 0.3108 Acc: 0.8839, val Loss: 0.3541 Acc: 0.8717\n",
            "Epoch  8/25: train Loss: 0.2972 Acc: 0.8881, val Loss: 0.3690 Acc: 0.8679\n",
            "Epoch  9/25: train Loss: 0.2886 Acc: 0.8917, val Loss: 0.3777 Acc: 0.8681\n",
            "Epoch 10/25: train Loss: 0.2831 Acc: 0.8925, val Loss: 0.3629 Acc: 0.8686\n",
            "Epoch 11/25: train Loss: 0.2780 Acc: 0.8945, val Loss: 0.3721 Acc: 0.8673\n",
            "Epoch 12/25: train Loss: 0.2718 Acc: 0.8981, val Loss: 0.3609 Acc: 0.8739\n",
            "Epoch 13/25: train Loss: 0.2688 Acc: 0.8992, val Loss: 0.4122 Acc: 0.8681\n",
            "Epoch 14/25: train Loss: 0.2569 Acc: 0.9030, val Loss: 0.3842 Acc: 0.8709\n",
            "Epoch 15/25: train Loss: 0.2561 Acc: 0.9027, val Loss: 0.4091 Acc: 0.8679\n",
            "Epoch 16/25: train Loss: 0.2541 Acc: 0.9044, val Loss: 0.3639 Acc: 0.8727\n",
            "Epoch 17/25: train Loss: 0.2541 Acc: 0.9049, val Loss: 0.4286 Acc: 0.8651\n",
            "Epoch 18/25: train Loss: 0.2508 Acc: 0.9054, val Loss: 0.3732 Acc: 0.8713\n",
            "Epoch 19/25: train Loss: 0.2532 Acc: 0.9043, val Loss: 0.3781 Acc: 0.8710\n",
            "Epoch 20/25: train Loss: 0.2493 Acc: 0.9062, val Loss: 0.3758 Acc: 0.8730\n",
            "Epoch 21/25: train Loss: 0.2508 Acc: 0.9055, val Loss: 0.3551 Acc: 0.8754\n",
            "Epoch 22/25: train Loss: 0.2511 Acc: 0.9058, val Loss: 0.3388 Acc: 0.8785\n",
            "Epoch 23/25: train Loss: 0.2492 Acc: 0.9056, val Loss: 0.3609 Acc: 0.8754\n",
            "Epoch 24/25: train Loss: 0.2518 Acc: 0.9056, val Loss: 0.3657 Acc: 0.8735\n",
            "Epoch 25/25: train Loss: 0.2495 Acc: 0.9062, val Loss: 0.3808 Acc: 0.8705\n",
            "\n",
            "Training complete in 295m 13s\n",
            "Best val Acc: 0.8785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxLwIlpx52_x"
      },
      "source": [
        "# Reload the data\n",
        "We are now going beyond the baseline training and evaluation. We will begin by reloading the data with better normalization and transformers. We will now introduce augmentations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iU8XtD8XDR"
      },
      "source": [
        "One of the transformers is an augmention holding the current state of the art for Image Classification, i.e. [Random Erasing](https://paperswithcode.com/paper/random-erasing-data-augmentation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIafRNGP53Wj"
      },
      "source": [
        "# taking the mean and std values from ImageNet training for normalization\n",
        "mean_values = [0.3297, 0.3819, 0.3637]\n",
        "std_values = [0.1816, 0.1887, 0.1877]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_values, std_values)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_values, std_values)\n",
        "])\n",
        "\n",
        "trainset = FashionMNIST(root = './data', train = True, download = True, transform = train_transform)\n",
        "trainloader = DataLoader(trainset, batch_size = 32, shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = FashionMNIST(root = './data', train = False, download = True, transform = test_transform)\n",
        "testloader = DataLoader(testset, batch_size = 32, shuffle = False, num_workers = 2)\n",
        "\n",
        "dataloaders = {'train': trainloader,\n",
        "               'val'  : testloader}\n",
        "dataset_sizes = {'train': len(trainset),\n",
        "                 'val'  : len(testset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p4PUBtIdmVM"
      },
      "source": [
        "While we're at it, let's give CNN another try, just to compare for the previous methods and the upcoming methods' performances.\n",
        "<br>\n",
        "Remember that CNN's best val accuracy was 0.9052 in the baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYiUc2fXduJW"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size = 5, padding = 2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size = 5, padding = 2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Linear(16*16*32, 10)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = input_tensor.unsqueeze(0)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC5utgPdePfd",
        "outputId": "d26c8a40-2265-4ad5-e987-c9f086eeec1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "cnn = CNN().to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(cnn.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "cnn_model = train_model(cnn, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4886 Acc: 0.8266, val Loss: 0.3708 Acc: 0.8648\n",
            "Epoch  2/25: train Loss: 0.3578 Acc: 0.8723, val Loss: 0.3373 Acc: 0.8772\n",
            "Epoch  3/25: train Loss: 0.3267 Acc: 0.8833, val Loss: 0.3125 Acc: 0.8894\n",
            "Epoch  4/25: train Loss: 0.3087 Acc: 0.8895, val Loss: 0.3276 Acc: 0.8837\n",
            "Epoch  5/25: train Loss: 0.2929 Acc: 0.8947, val Loss: 0.3073 Acc: 0.8905\n",
            "Epoch  6/25: train Loss: 0.2812 Acc: 0.8981, val Loss: 0.2930 Acc: 0.8955\n",
            "Epoch  7/25: train Loss: 0.2518 Acc: 0.9112, val Loss: 0.2677 Acc: 0.9046\n",
            "Epoch  8/25: train Loss: 0.2460 Acc: 0.9130, val Loss: 0.2668 Acc: 0.9041\n",
            "Epoch  9/25: train Loss: 0.2464 Acc: 0.9123, val Loss: 0.2668 Acc: 0.9050\n",
            "Epoch 10/25: train Loss: 0.2433 Acc: 0.9130, val Loss: 0.2621 Acc: 0.9066\n",
            "Epoch 11/25: train Loss: 0.2430 Acc: 0.9143, val Loss: 0.2625 Acc: 0.9058\n",
            "Epoch 12/25: train Loss: 0.2395 Acc: 0.9156, val Loss: 0.2628 Acc: 0.9068\n",
            "Epoch 13/25: train Loss: 0.2390 Acc: 0.9154, val Loss: 0.2621 Acc: 0.9058\n",
            "Epoch 14/25: train Loss: 0.2368 Acc: 0.9158, val Loss: 0.2594 Acc: 0.9075\n",
            "Epoch 15/25: train Loss: 0.2352 Acc: 0.9165, val Loss: 0.2588 Acc: 0.9081\n",
            "Epoch 16/25: train Loss: 0.2369 Acc: 0.9169, val Loss: 0.2588 Acc: 0.9070\n",
            "Epoch 17/25: train Loss: 0.2351 Acc: 0.9168, val Loss: 0.2586 Acc: 0.9074\n",
            "Epoch 18/25: train Loss: 0.2359 Acc: 0.9163, val Loss: 0.2586 Acc: 0.9078\n",
            "Epoch 19/25: train Loss: 0.2342 Acc: 0.9174, val Loss: 0.2584 Acc: 0.9075\n",
            "Epoch 20/25: train Loss: 0.2354 Acc: 0.9176, val Loss: 0.2580 Acc: 0.9077\n",
            "Epoch 21/25: train Loss: 0.2355 Acc: 0.9159, val Loss: 0.2578 Acc: 0.9078\n",
            "Epoch 22/25: train Loss: 0.2342 Acc: 0.9175, val Loss: 0.2585 Acc: 0.9075\n",
            "Epoch 23/25: train Loss: 0.2348 Acc: 0.9176, val Loss: 0.2579 Acc: 0.9080\n",
            "Epoch 24/25: train Loss: 0.2343 Acc: 0.9171, val Loss: 0.2582 Acc: 0.9077\n",
            "Epoch 25/25: train Loss: 0.2343 Acc: 0.9178, val Loss: 0.2581 Acc: 0.9086\n",
            "\n",
            "Training complete in 12m 31s\n",
            "Best val Acc: 0.9086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1vHB-mteXBK"
      },
      "source": [
        "Notice that after changing how we load the data, we have gained slightly more accuracy. Now let's move on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6zuJ9MH-TcR"
      },
      "source": [
        "# Training and Evaluation with Transfer Learning\n",
        "Instead of random weight initialization, we transfer learned weights of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMXKR3G7t0ul",
        "outputId": "7711587d-78d3-435e-aa19-5682f7713ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "VGG16 = models.vgg16(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(VGG16.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "VGG16_model = train_model(VGG16, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4962 Acc: 0.8374, val Loss: 0.3293 Acc: 0.8882\n",
            "Epoch  2/25: train Loss: 0.2597 Acc: 0.9079, val Loss: 0.2359 Acc: 0.9159\n",
            "Epoch  3/25: train Loss: 0.2189 Acc: 0.9219, val Loss: 0.2273 Acc: 0.9195\n",
            "Epoch  4/25: train Loss: 0.1914 Acc: 0.9301, val Loss: 0.1980 Acc: 0.9274\n",
            "Epoch  5/25: train Loss: 0.1717 Acc: 0.9373, val Loss: 0.2122 Acc: 0.9259\n",
            "Epoch  6/25: train Loss: 0.1617 Acc: 0.9416, val Loss: 0.1851 Acc: 0.9361\n",
            "Epoch  7/25: train Loss: 0.1197 Acc: 0.9572, val Loss: 0.1680 Acc: 0.9405\n",
            "Epoch  8/25: train Loss: 0.1144 Acc: 0.9594, val Loss: 0.1672 Acc: 0.9425\n",
            "Epoch  9/25: train Loss: 0.1092 Acc: 0.9612, val Loss: 0.1694 Acc: 0.9424\n",
            "Epoch 10/25: train Loss: 0.1068 Acc: 0.9619, val Loss: 0.1679 Acc: 0.9421\n",
            "Epoch 11/25: train Loss: 0.1043 Acc: 0.9623, val Loss: 0.1649 Acc: 0.9439\n",
            "Epoch 12/25: train Loss: 0.1007 Acc: 0.9641, val Loss: 0.1661 Acc: 0.9441\n",
            "Epoch 13/25: train Loss: 0.0985 Acc: 0.9648, val Loss: 0.1688 Acc: 0.9449\n",
            "Epoch 14/25: train Loss: 0.0937 Acc: 0.9658, val Loss: 0.1668 Acc: 0.9453\n",
            "Epoch 15/25: train Loss: 0.0923 Acc: 0.9667, val Loss: 0.1669 Acc: 0.9452\n",
            "Epoch 16/25: train Loss: 0.0916 Acc: 0.9673, val Loss: 0.1670 Acc: 0.9451\n",
            "Epoch 17/25: train Loss: 0.0899 Acc: 0.9674, val Loss: 0.1677 Acc: 0.9456\n",
            "Epoch 18/25: train Loss: 0.0909 Acc: 0.9677, val Loss: 0.1682 Acc: 0.9454\n",
            "Epoch 19/25: train Loss: 0.0916 Acc: 0.9671, val Loss: 0.1677 Acc: 0.9454\n",
            "Epoch 20/25: train Loss: 0.0896 Acc: 0.9677, val Loss: 0.1681 Acc: 0.9454\n",
            "Epoch 21/25: train Loss: 0.0889 Acc: 0.9684, val Loss: 0.1682 Acc: 0.9455\n",
            "Epoch 22/25: train Loss: 0.0902 Acc: 0.9680, val Loss: 0.1681 Acc: 0.9454\n",
            "Epoch 23/25: train Loss: 0.0895 Acc: 0.9680, val Loss: 0.1682 Acc: 0.9455\n",
            "Epoch 24/25: train Loss: 0.0897 Acc: 0.9682, val Loss: 0.1681 Acc: 0.9453\n",
            "Epoch 25/25: train Loss: 0.0904 Acc: 0.9675, val Loss: 0.1681 Acc: 0.9452\n",
            "\n",
            "Training complete in 68m 21s\n",
            "Best val Acc: 0.9456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TblvNLfuBxAO",
        "outputId": "70fed992-6768-42aa-b91c-a0f6ca118b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "ResNet18 = models.resnet18(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNet18.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNet18_model = train_model(ResNet18, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4706 Acc: 0.8548, val Loss: 0.2545 Acc: 0.9093\n",
            "Epoch  2/25: train Loss: 0.2615 Acc: 0.9064, val Loss: 0.2312 Acc: 0.9197\n",
            "Epoch  3/25: train Loss: 0.2156 Acc: 0.9218, val Loss: 0.2037 Acc: 0.9261\n",
            "Epoch  4/25: train Loss: 0.1936 Acc: 0.9286, val Loss: 0.2012 Acc: 0.9296\n",
            "Epoch  5/25: train Loss: 0.1805 Acc: 0.9344, val Loss: 0.2053 Acc: 0.9281\n",
            "Epoch  6/25: train Loss: 0.1655 Acc: 0.9392, val Loss: 0.1947 Acc: 0.9319\n",
            "Epoch  7/25: train Loss: 0.1334 Acc: 0.9507, val Loss: 0.1772 Acc: 0.9366\n",
            "Epoch  8/25: train Loss: 0.1239 Acc: 0.9540, val Loss: 0.1751 Acc: 0.9385\n",
            "Epoch  9/25: train Loss: 0.1196 Acc: 0.9560, val Loss: 0.1720 Acc: 0.9397\n",
            "Epoch 10/25: train Loss: 0.1161 Acc: 0.9573, val Loss: 0.1720 Acc: 0.9413\n",
            "Epoch 11/25: train Loss: 0.1148 Acc: 0.9578, val Loss: 0.1716 Acc: 0.9416\n",
            "Epoch 12/25: train Loss: 0.1108 Acc: 0.9591, val Loss: 0.1716 Acc: 0.9410\n",
            "Epoch 13/25: train Loss: 0.1080 Acc: 0.9601, val Loss: 0.1753 Acc: 0.9412\n",
            "Epoch 14/25: train Loss: 0.1041 Acc: 0.9617, val Loss: 0.1736 Acc: 0.9400\n",
            "Epoch 15/25: train Loss: 0.1036 Acc: 0.9618, val Loss: 0.1723 Acc: 0.9410\n",
            "Epoch 16/25: train Loss: 0.1038 Acc: 0.9624, val Loss: 0.1721 Acc: 0.9406\n",
            "Epoch 17/25: train Loss: 0.1029 Acc: 0.9621, val Loss: 0.1717 Acc: 0.9425\n",
            "Epoch 18/25: train Loss: 0.1018 Acc: 0.9629, val Loss: 0.1719 Acc: 0.9414\n",
            "Epoch 19/25: train Loss: 0.1019 Acc: 0.9630, val Loss: 0.1737 Acc: 0.9413\n",
            "Epoch 20/25: train Loss: 0.1014 Acc: 0.9628, val Loss: 0.1720 Acc: 0.9423\n",
            "Epoch 21/25: train Loss: 0.1003 Acc: 0.9634, val Loss: 0.1710 Acc: 0.9413\n",
            "Epoch 22/25: train Loss: 0.1011 Acc: 0.9632, val Loss: 0.1729 Acc: 0.9406\n",
            "Epoch 23/25: train Loss: 0.1012 Acc: 0.9627, val Loss: 0.1720 Acc: 0.9415\n",
            "Epoch 24/25: train Loss: 0.1004 Acc: 0.9637, val Loss: 0.1729 Acc: 0.9399\n",
            "Epoch 25/25: train Loss: 0.0996 Acc: 0.9627, val Loss: 0.1724 Acc: 0.9410\n",
            "\n",
            "Training complete in 24m 53s\n",
            "Best val Acc: 0.9425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYS423JyBw99",
        "outputId": "81397419-8752-45f5-d0e4-9211c1491d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "alexNet = models.alexnet(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(alexNet.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "alexNet_model = train_model(alexNet, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.5660 Acc: 0.8117, val Loss: 0.3514 Acc: 0.8776\n",
            "Epoch  2/25: train Loss: 0.3543 Acc: 0.8717, val Loss: 0.3637 Acc: 0.8687\n",
            "Epoch  3/25: train Loss: 0.3117 Acc: 0.8863, val Loss: 0.3299 Acc: 0.8823\n",
            "Epoch  4/25: train Loss: 0.2858 Acc: 0.8938, val Loss: 0.2980 Acc: 0.8952\n",
            "Epoch  5/25: train Loss: 0.2697 Acc: 0.8998, val Loss: 0.2870 Acc: 0.8925\n",
            "Epoch  6/25: train Loss: 0.2522 Acc: 0.9066, val Loss: 0.2767 Acc: 0.9028\n",
            "Epoch  7/25: train Loss: 0.2061 Acc: 0.9226, val Loss: 0.2522 Acc: 0.9114\n",
            "Epoch  8/25: train Loss: 0.1987 Acc: 0.9260, val Loss: 0.2463 Acc: 0.9133\n",
            "Epoch  9/25: train Loss: 0.1968 Acc: 0.9263, val Loss: 0.2485 Acc: 0.9130\n",
            "Epoch 10/25: train Loss: 0.1927 Acc: 0.9280, val Loss: 0.2482 Acc: 0.9136\n",
            "Epoch 11/25: train Loss: 0.1898 Acc: 0.9287, val Loss: 0.2490 Acc: 0.9123\n",
            "Epoch 12/25: train Loss: 0.1864 Acc: 0.9296, val Loss: 0.2447 Acc: 0.9132\n",
            "Epoch 13/25: train Loss: 0.1833 Acc: 0.9312, val Loss: 0.2490 Acc: 0.9149\n",
            "Epoch 14/25: train Loss: 0.1810 Acc: 0.9318, val Loss: 0.2442 Acc: 0.9152\n",
            "Epoch 15/25: train Loss: 0.1811 Acc: 0.9334, val Loss: 0.2437 Acc: 0.9151\n",
            "Epoch 16/25: train Loss: 0.1798 Acc: 0.9328, val Loss: 0.2430 Acc: 0.9157\n",
            "Epoch 17/25: train Loss: 0.1778 Acc: 0.9339, val Loss: 0.2429 Acc: 0.9156\n",
            "Epoch 18/25: train Loss: 0.1792 Acc: 0.9333, val Loss: 0.2441 Acc: 0.9153\n",
            "Epoch 19/25: train Loss: 0.1779 Acc: 0.9333, val Loss: 0.2431 Acc: 0.9156\n",
            "Epoch 20/25: train Loss: 0.1771 Acc: 0.9344, val Loss: 0.2436 Acc: 0.9160\n",
            "Epoch 21/25: train Loss: 0.1785 Acc: 0.9335, val Loss: 0.2435 Acc: 0.9159\n",
            "Epoch 22/25: train Loss: 0.1753 Acc: 0.9344, val Loss: 0.2435 Acc: 0.9157\n",
            "Epoch 23/25: train Loss: 0.1768 Acc: 0.9336, val Loss: 0.2435 Acc: 0.9157\n",
            "Epoch 24/25: train Loss: 0.1752 Acc: 0.9338, val Loss: 0.2434 Acc: 0.9161\n",
            "Epoch 25/25: train Loss: 0.1775 Acc: 0.9330, val Loss: 0.2434 Acc: 0.9161\n",
            "\n",
            "Training complete in 18m 48s\n",
            "Best val Acc: 0.9161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFiEO6GlBw6U",
        "outputId": "857e9e15-5d22-486f-9598-18303ecae041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "squeezeNet = models.squeezenet1_1(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(squeezeNet.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "squeezeNet_model = train_model(squeezeNet, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.8958 Acc: 0.6788, val Loss: 0.4915 Acc: 0.8229\n",
            "Epoch  2/25: train Loss: 0.4488 Acc: 0.8382, val Loss: 0.3675 Acc: 0.8643\n",
            "Epoch  3/25: train Loss: 0.3778 Acc: 0.8641, val Loss: 0.3362 Acc: 0.8794\n",
            "Epoch  4/25: train Loss: 0.3403 Acc: 0.8771, val Loss: 0.2964 Acc: 0.8899\n",
            "Epoch  5/25: train Loss: 0.3137 Acc: 0.8863, val Loss: 0.2995 Acc: 0.8960\n",
            "Epoch  6/25: train Loss: 0.2974 Acc: 0.8928, val Loss: 0.2784 Acc: 0.8970\n",
            "Epoch  7/25: train Loss: 0.2485 Acc: 0.9096, val Loss: 0.2484 Acc: 0.9117\n",
            "Epoch  8/25: train Loss: 0.2412 Acc: 0.9118, val Loss: 0.2467 Acc: 0.9128\n",
            "Epoch  9/25: train Loss: 0.2403 Acc: 0.9116, val Loss: 0.2432 Acc: 0.9123\n",
            "Epoch 10/25: train Loss: 0.2375 Acc: 0.9138, val Loss: 0.2423 Acc: 0.9122\n",
            "Epoch 11/25: train Loss: 0.2352 Acc: 0.9136, val Loss: 0.2423 Acc: 0.9137\n",
            "Epoch 12/25: train Loss: 0.2321 Acc: 0.9150, val Loss: 0.2395 Acc: 0.9141\n",
            "Epoch 13/25: train Loss: 0.2308 Acc: 0.9153, val Loss: 0.2407 Acc: 0.9135\n",
            "Epoch 14/25: train Loss: 0.2237 Acc: 0.9185, val Loss: 0.2365 Acc: 0.9146\n",
            "Epoch 15/25: train Loss: 0.2234 Acc: 0.9184, val Loss: 0.2362 Acc: 0.9159\n",
            "Epoch 16/25: train Loss: 0.2253 Acc: 0.9185, val Loss: 0.2361 Acc: 0.9157\n",
            "Epoch 17/25: train Loss: 0.2234 Acc: 0.9190, val Loss: 0.2365 Acc: 0.9158\n",
            "Epoch 18/25: train Loss: 0.2232 Acc: 0.9183, val Loss: 0.2360 Acc: 0.9147\n",
            "Epoch 19/25: train Loss: 0.2226 Acc: 0.9187, val Loss: 0.2349 Acc: 0.9148\n",
            "Epoch 20/25: train Loss: 0.2219 Acc: 0.9199, val Loss: 0.2347 Acc: 0.9152\n",
            "Epoch 21/25: train Loss: 0.2219 Acc: 0.9188, val Loss: 0.2351 Acc: 0.9154\n",
            "Epoch 22/25: train Loss: 0.2215 Acc: 0.9190, val Loss: 0.2352 Acc: 0.9152\n",
            "Epoch 23/25: train Loss: 0.2218 Acc: 0.9191, val Loss: 0.2353 Acc: 0.9153\n",
            "Epoch 24/25: train Loss: 0.2230 Acc: 0.9180, val Loss: 0.2352 Acc: 0.9153\n",
            "Epoch 25/25: train Loss: 0.2209 Acc: 0.9199, val Loss: 0.2352 Acc: 0.9153\n",
            "\n",
            "Training complete in 17m 13s\n",
            "Best val Acc: 0.9159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roLOP9GWBw2-",
        "outputId": "a3c5d1a6-12c9-4fd3-be38-5a3b3f95cff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "denseNet121 = models.densenet121(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(denseNet121.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "denseNet121_model = train_model(denseNet121, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4492 Acc: 0.8625, val Loss: 0.2544 Acc: 0.9103\n",
            "Epoch  2/25: train Loss: 0.2415 Acc: 0.9133, val Loss: 0.2227 Acc: 0.9199\n",
            "Epoch  3/25: train Loss: 0.2014 Acc: 0.9275, val Loss: 0.2045 Acc: 0.9296\n",
            "Epoch  4/25: train Loss: 0.1791 Acc: 0.9366, val Loss: 0.1862 Acc: 0.9339\n",
            "Epoch  5/25: train Loss: 0.1631 Acc: 0.9410, val Loss: 0.1876 Acc: 0.9351\n",
            "Epoch  6/25: train Loss: 0.1517 Acc: 0.9436, val Loss: 0.1861 Acc: 0.9364\n",
            "Epoch  7/25: train Loss: 0.1174 Acc: 0.9575, val Loss: 0.1691 Acc: 0.9424\n",
            "Epoch  8/25: train Loss: 0.1109 Acc: 0.9603, val Loss: 0.1673 Acc: 0.9426\n",
            "Epoch  9/25: train Loss: 0.1041 Acc: 0.9627, val Loss: 0.1678 Acc: 0.9431\n",
            "Epoch 10/25: train Loss: 0.1007 Acc: 0.9630, val Loss: 0.1684 Acc: 0.9425\n",
            "Epoch 11/25: train Loss: 0.0986 Acc: 0.9641, val Loss: 0.1695 Acc: 0.9446\n",
            "Epoch 12/25: train Loss: 0.0959 Acc: 0.9659, val Loss: 0.1724 Acc: 0.9427\n",
            "Epoch 13/25: train Loss: 0.0903 Acc: 0.9675, val Loss: 0.1741 Acc: 0.9414\n",
            "Epoch 14/25: train Loss: 0.0893 Acc: 0.9683, val Loss: 0.1714 Acc: 0.9422\n",
            "Epoch 15/25: train Loss: 0.0864 Acc: 0.9691, val Loss: 0.1704 Acc: 0.9414\n",
            "Epoch 16/25: train Loss: 0.0865 Acc: 0.9693, val Loss: 0.1729 Acc: 0.9425\n",
            "Epoch 17/25: train Loss: 0.0854 Acc: 0.9699, val Loss: 0.1713 Acc: 0.9421\n",
            "Epoch 18/25: train Loss: 0.0852 Acc: 0.9695, val Loss: 0.1723 Acc: 0.9418\n",
            "Epoch 19/25: train Loss: 0.0872 Acc: 0.9687, val Loss: 0.1718 Acc: 0.9420\n",
            "Epoch 20/25: train Loss: 0.0849 Acc: 0.9698, val Loss: 0.1718 Acc: 0.9418\n",
            "Epoch 21/25: train Loss: 0.0843 Acc: 0.9694, val Loss: 0.1724 Acc: 0.9419\n",
            "Epoch 22/25: train Loss: 0.0847 Acc: 0.9695, val Loss: 0.1724 Acc: 0.9416\n",
            "Epoch 23/25: train Loss: 0.0859 Acc: 0.9691, val Loss: 0.1724 Acc: 0.9419\n",
            "Epoch 24/25: train Loss: 0.0841 Acc: 0.9697, val Loss: 0.1719 Acc: 0.9425\n",
            "Epoch 25/25: train Loss: 0.0843 Acc: 0.9694, val Loss: 0.1726 Acc: 0.9421\n",
            "\n",
            "Training complete in 62m 58s\n",
            "Best val Acc: 0.9446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eznbo6qBwxF",
        "outputId": "bd1f4238-53d9-42b4-ad75-69bd3fdd7489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "denseNet161 = models.densenet161(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(denseNet161.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "denseNet161_model = train_model(denseNet161, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4041 Acc: 0.8713, val Loss: 0.2558 Acc: 0.9119\n",
            "Epoch  2/25: train Loss: 0.2269 Acc: 0.9179, val Loss: 0.2045 Acc: 0.9264\n",
            "Epoch  3/25: train Loss: 0.1879 Acc: 0.9318, val Loss: 0.1955 Acc: 0.9325\n",
            "Epoch  4/25: train Loss: 0.1641 Acc: 0.9406, val Loss: 0.1791 Acc: 0.9379\n",
            "Epoch  5/25: train Loss: 0.1471 Acc: 0.9458, val Loss: 0.1840 Acc: 0.9354\n",
            "Epoch  6/25: train Loss: 0.1331 Acc: 0.9512, val Loss: 0.1882 Acc: 0.9362\n",
            "Epoch  7/25: train Loss: 0.0957 Acc: 0.9654, val Loss: 0.1660 Acc: 0.9455\n",
            "Epoch  8/25: train Loss: 0.0871 Acc: 0.9681, val Loss: 0.1653 Acc: 0.9459\n",
            "Epoch  9/25: train Loss: 0.0806 Acc: 0.9714, val Loss: 0.1680 Acc: 0.9458\n",
            "Epoch 10/25: train Loss: 0.0767 Acc: 0.9730, val Loss: 0.1692 Acc: 0.9461\n",
            "Epoch 11/25: train Loss: 0.0740 Acc: 0.9737, val Loss: 0.1709 Acc: 0.9474\n",
            "Epoch 12/25: train Loss: 0.0698 Acc: 0.9747, val Loss: 0.1736 Acc: 0.9442\n",
            "Epoch 13/25: train Loss: 0.0661 Acc: 0.9763, val Loss: 0.1726 Acc: 0.9472\n",
            "Epoch 14/25: train Loss: 0.0629 Acc: 0.9773, val Loss: 0.1746 Acc: 0.9464\n",
            "Epoch 15/25: train Loss: 0.0596 Acc: 0.9793, val Loss: 0.1749 Acc: 0.9463\n",
            "Epoch 16/25: train Loss: 0.0613 Acc: 0.9779, val Loss: 0.1755 Acc: 0.9457\n",
            "Epoch 17/25: train Loss: 0.0603 Acc: 0.9787, val Loss: 0.1735 Acc: 0.9463\n",
            "Epoch 18/25: train Loss: 0.0601 Acc: 0.9783, val Loss: 0.1745 Acc: 0.9463\n",
            "Epoch 19/25: train Loss: 0.0596 Acc: 0.9793, val Loss: 0.1761 Acc: 0.9465\n",
            "Epoch 20/25: train Loss: 0.0591 Acc: 0.9794, val Loss: 0.1744 Acc: 0.9464\n",
            "Epoch 21/25: train Loss: 0.0580 Acc: 0.9799, val Loss: 0.1742 Acc: 0.9470\n",
            "Epoch 22/25: train Loss: 0.0587 Acc: 0.9786, val Loss: 0.1728 Acc: 0.9457\n",
            "Epoch 23/25: train Loss: 0.0581 Acc: 0.9791, val Loss: 0.1738 Acc: 0.9470\n",
            "Epoch 24/25: train Loss: 0.0576 Acc: 0.9799, val Loss: 0.1761 Acc: 0.9471\n",
            "Epoch 25/25: train Loss: 0.0584 Acc: 0.9791, val Loss: 0.1744 Acc: 0.9451\n",
            "\n",
            "Training complete in 106m 3s\n",
            "Best val Acc: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCUZ_pCzBwto",
        "outputId": "1ce9229b-28bf-4847-e568-933139849038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "denseNet169 = models.densenet169(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(denseNet169.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "denseNet169_model = train_model(denseNet169, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4382 Acc: 0.8631, val Loss: 0.2474 Acc: 0.9096\n",
            "Epoch  2/25: train Loss: 0.2464 Acc: 0.9116, val Loss: 0.2258 Acc: 0.9175\n",
            "Epoch  3/25: train Loss: 0.2039 Acc: 0.9259, val Loss: 0.1937 Acc: 0.9306\n",
            "Epoch  4/25: train Loss: 0.1823 Acc: 0.9332, val Loss: 0.1913 Acc: 0.9339\n",
            "Epoch  5/25: train Loss: 0.1648 Acc: 0.9397, val Loss: 0.1940 Acc: 0.9298\n",
            "Epoch  6/25: train Loss: 0.1507 Acc: 0.9441, val Loss: 0.1867 Acc: 0.9337\n",
            "Epoch  7/25: train Loss: 0.1175 Acc: 0.9566, val Loss: 0.1686 Acc: 0.9411\n",
            "Epoch  8/25: train Loss: 0.1077 Acc: 0.9611, val Loss: 0.1689 Acc: 0.9412\n",
            "Epoch  9/25: train Loss: 0.1019 Acc: 0.9630, val Loss: 0.1702 Acc: 0.9416\n",
            "Epoch 10/25: train Loss: 0.0972 Acc: 0.9646, val Loss: 0.1729 Acc: 0.9412\n",
            "Epoch 11/25: train Loss: 0.0950 Acc: 0.9656, val Loss: 0.1732 Acc: 0.9409\n",
            "Epoch 12/25: train Loss: 0.0914 Acc: 0.9671, val Loss: 0.1713 Acc: 0.9437\n",
            "Epoch 13/25: train Loss: 0.0877 Acc: 0.9674, val Loss: 0.1735 Acc: 0.9422\n",
            "Epoch 14/25: train Loss: 0.0838 Acc: 0.9695, val Loss: 0.1721 Acc: 0.9432\n",
            "Epoch 15/25: train Loss: 0.0826 Acc: 0.9697, val Loss: 0.1717 Acc: 0.9438\n",
            "Epoch 16/25: train Loss: 0.0818 Acc: 0.9706, val Loss: 0.1765 Acc: 0.9419\n",
            "Epoch 17/25: train Loss: 0.0815 Acc: 0.9700, val Loss: 0.1738 Acc: 0.9417\n",
            "Epoch 18/25: train Loss: 0.0804 Acc: 0.9712, val Loss: 0.1738 Acc: 0.9430\n",
            "Epoch 19/25: train Loss: 0.0796 Acc: 0.9710, val Loss: 0.1736 Acc: 0.9432\n",
            "Epoch 20/25: train Loss: 0.0804 Acc: 0.9709, val Loss: 0.1739 Acc: 0.9431\n",
            "Epoch 21/25: train Loss: 0.0808 Acc: 0.9711, val Loss: 0.1722 Acc: 0.9434\n",
            "Epoch 22/25: train Loss: 0.0787 Acc: 0.9718, val Loss: 0.1732 Acc: 0.9444\n",
            "Epoch 23/25: train Loss: 0.0787 Acc: 0.9716, val Loss: 0.1754 Acc: 0.9425\n",
            "Epoch 24/25: train Loss: 0.0789 Acc: 0.9714, val Loss: 0.1740 Acc: 0.9439\n",
            "Epoch 25/25: train Loss: 0.0795 Acc: 0.9711, val Loss: 0.1744 Acc: 0.9425\n",
            "\n",
            "Training complete in 191m 29s\n",
            "Best val Acc: 0.9444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri6e-_EnBwas",
        "outputId": "a106b9a9-b634-4d64-e090-f666c4ef45a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "googleNet = models.googlenet(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(googleNet.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "googleNet_model = train_model(googleNet, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.5340 Acc: 0.8360, val Loss: 0.2736 Acc: 0.9009\n",
            "Epoch  2/25: train Loss: 0.2942 Acc: 0.8955, val Loss: 0.2465 Acc: 0.9099\n",
            "Epoch  3/25: train Loss: 0.2525 Acc: 0.9101, val Loss: 0.2258 Acc: 0.9191\n",
            "Epoch  4/25: train Loss: 0.2260 Acc: 0.9185, val Loss: 0.2226 Acc: 0.9215\n",
            "Epoch  5/25: train Loss: 0.2061 Acc: 0.9249, val Loss: 0.2032 Acc: 0.9261\n",
            "Epoch  6/25: train Loss: 0.1899 Acc: 0.9310, val Loss: 0.1996 Acc: 0.9291\n",
            "Epoch  7/25: train Loss: 0.1608 Acc: 0.9416, val Loss: 0.1892 Acc: 0.9327\n",
            "Epoch  8/25: train Loss: 0.1580 Acc: 0.9416, val Loss: 0.1870 Acc: 0.9355\n",
            "Epoch  9/25: train Loss: 0.1534 Acc: 0.9440, val Loss: 0.1873 Acc: 0.9350\n",
            "Epoch 10/25: train Loss: 0.1489 Acc: 0.9459, val Loss: 0.1857 Acc: 0.9358\n",
            "Epoch 11/25: train Loss: 0.1489 Acc: 0.9461, val Loss: 0.1860 Acc: 0.9343\n",
            "Epoch 12/25: train Loss: 0.1441 Acc: 0.9476, val Loss: 0.1844 Acc: 0.9344\n",
            "Epoch 13/25: train Loss: 0.1414 Acc: 0.9481, val Loss: 0.1882 Acc: 0.9340\n",
            "Epoch 14/25: train Loss: 0.1385 Acc: 0.9504, val Loss: 0.1855 Acc: 0.9344\n",
            "Epoch 15/25: train Loss: 0.1407 Acc: 0.9479, val Loss: 0.1852 Acc: 0.9350\n",
            "Epoch 16/25: train Loss: 0.1389 Acc: 0.9492, val Loss: 0.1841 Acc: 0.9354\n",
            "Epoch 17/25: train Loss: 0.1391 Acc: 0.9493, val Loss: 0.1839 Acc: 0.9368\n",
            "Epoch 18/25: train Loss: 0.1382 Acc: 0.9497, val Loss: 0.1838 Acc: 0.9358\n",
            "Epoch 19/25: train Loss: 0.1388 Acc: 0.9497, val Loss: 0.1839 Acc: 0.9358\n",
            "Epoch 20/25: train Loss: 0.1358 Acc: 0.9499, val Loss: 0.1839 Acc: 0.9346\n",
            "Epoch 21/25: train Loss: 0.1389 Acc: 0.9492, val Loss: 0.1854 Acc: 0.9343\n",
            "Epoch 22/25: train Loss: 0.1380 Acc: 0.9487, val Loss: 0.1851 Acc: 0.9356\n",
            "Epoch 23/25: train Loss: 0.1368 Acc: 0.9500, val Loss: 0.1840 Acc: 0.9355\n",
            "Epoch 24/25: train Loss: 0.1368 Acc: 0.9499, val Loss: 0.1831 Acc: 0.9351\n",
            "Epoch 25/25: train Loss: 0.1357 Acc: 0.9503, val Loss: 0.1837 Acc: 0.9357\n",
            "\n",
            "Training complete in 77m 20s\n",
            "Best val Acc: 0.9368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oaGM5fhIOU6",
        "outputId": "e1d96143-219e-4760-f96a-684e6eac6a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "mobileNet = models.mobilenet_v2(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(mobileNet.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "mobileNet_model = train_model(mobileNet, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.5325 Acc: 0.8349, val Loss: 0.3260 Acc: 0.8832\n",
            "Epoch  2/25: train Loss: 0.2903 Acc: 0.8954, val Loss: 0.2352 Acc: 0.9156\n",
            "Epoch  3/25: train Loss: 0.2448 Acc: 0.9118, val Loss: 0.2585 Acc: 0.9078\n",
            "Epoch  4/25: train Loss: 0.2206 Acc: 0.9209, val Loss: 0.2180 Acc: 0.9214\n",
            "Epoch  5/25: train Loss: 0.2044 Acc: 0.9238, val Loss: 0.2049 Acc: 0.9278\n",
            "Epoch  6/25: train Loss: 0.1930 Acc: 0.9294, val Loss: 0.1978 Acc: 0.9289\n",
            "Epoch  7/25: train Loss: 0.1606 Acc: 0.9403, val Loss: 0.1801 Acc: 0.9355\n",
            "Epoch  8/25: train Loss: 0.1518 Acc: 0.9437, val Loss: 0.1781 Acc: 0.9363\n",
            "Epoch  9/25: train Loss: 0.1490 Acc: 0.9450, val Loss: 0.1775 Acc: 0.9364\n",
            "Epoch 10/25: train Loss: 0.1461 Acc: 0.9462, val Loss: 0.1752 Acc: 0.9385\n",
            "Epoch 11/25: train Loss: 0.1430 Acc: 0.9468, val Loss: 0.1752 Acc: 0.9383\n",
            "Epoch 12/25: train Loss: 0.1424 Acc: 0.9481, val Loss: 0.1749 Acc: 0.9382\n",
            "Epoch 13/25: train Loss: 0.1371 Acc: 0.9498, val Loss: 0.1746 Acc: 0.9385\n",
            "Epoch 14/25: train Loss: 0.1355 Acc: 0.9497, val Loss: 0.1755 Acc: 0.9391\n",
            "Epoch 15/25: train Loss: 0.1355 Acc: 0.9499, val Loss: 0.1737 Acc: 0.9396\n",
            "Epoch 16/25: train Loss: 0.1349 Acc: 0.9506, val Loss: 0.1760 Acc: 0.9381\n",
            "Epoch 17/25: train Loss: 0.1339 Acc: 0.9503, val Loss: 0.1744 Acc: 0.9390\n",
            "Epoch 18/25: train Loss: 0.1325 Acc: 0.9508, val Loss: 0.1747 Acc: 0.9380\n",
            "Epoch 19/25: train Loss: 0.1335 Acc: 0.9501, val Loss: 0.1744 Acc: 0.9388\n",
            "Epoch 20/25: train Loss: 0.1318 Acc: 0.9522, val Loss: 0.1741 Acc: 0.9393\n",
            "Epoch 21/25: train Loss: 0.1323 Acc: 0.9512, val Loss: 0.1740 Acc: 0.9398\n",
            "Epoch 22/25: train Loss: 0.1328 Acc: 0.9507, val Loss: 0.1742 Acc: 0.9401\n",
            "Epoch 23/25: train Loss: 0.1320 Acc: 0.9516, val Loss: 0.1734 Acc: 0.9397\n",
            "Epoch 24/25: train Loss: 0.1318 Acc: 0.9516, val Loss: 0.1726 Acc: 0.9401\n",
            "Epoch 25/25: train Loss: 0.1310 Acc: 0.9509, val Loss: 0.1747 Acc: 0.9399\n",
            "\n",
            "Training complete in 49m 53s\n",
            "Best val Acc: 0.9401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hIw4UPlIOPp",
        "outputId": "4803ce9a-ffff-41db-bd09-ee34dacf6318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "ResNext50 = models.resnext50_32x4d(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNext50.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNext50_model = train_model(ResNext50, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/25: train Loss: 0.4303 Acc: 0.8658, val Loss: 0.2387 Acc: 0.9115\n",
            "Epoch  2/25: train Loss: 0.2238 Acc: 0.9196, val Loss: 0.2070 Acc: 0.9248\n",
            "Epoch  3/25: train Loss: 0.1880 Acc: 0.9314, val Loss: 0.1988 Acc: 0.9318\n",
            "Epoch  4/25: train Loss: 0.1634 Acc: 0.9400, val Loss: 0.1911 Acc: 0.9328\n",
            "Epoch  5/25: train Loss: 0.1435 Acc: 0.9478, val Loss: 0.1821 Acc: 0.9392\n",
            "Epoch  6/25: train Loss: 0.1284 Acc: 0.9521, val Loss: 0.1785 Acc: 0.9374\n",
            "Epoch  7/25: train Loss: 0.0909 Acc: 0.9676, val Loss: 0.1664 Acc: 0.9441\n",
            "Epoch  8/25: train Loss: 0.0820 Acc: 0.9709, val Loss: 0.1661 Acc: 0.9442\n",
            "Epoch  9/25: train Loss: 0.0755 Acc: 0.9722, val Loss: 0.1690 Acc: 0.9457\n",
            "Epoch 10/25: train Loss: 0.0702 Acc: 0.9747, val Loss: 0.1694 Acc: 0.9457\n",
            "Epoch 11/25: train Loss: 0.0671 Acc: 0.9762, val Loss: 0.1717 Acc: 0.9452\n",
            "Epoch 12/25: train Loss: 0.0635 Acc: 0.9772, val Loss: 0.1762 Acc: 0.9447\n",
            "Epoch 13/25: train Loss: 0.0607 Acc: 0.9777, val Loss: 0.1771 Acc: 0.9475\n",
            "Epoch 14/25: train Loss: 0.0543 Acc: 0.9805, val Loss: 0.1782 Acc: 0.9473\n",
            "Epoch 15/25: train Loss: 0.0537 Acc: 0.9807, val Loss: 0.1779 Acc: 0.9469\n",
            "Epoch 16/25: train Loss: 0.0525 Acc: 0.9810, val Loss: 0.1774 Acc: 0.9470\n",
            "Epoch 17/25: train Loss: 0.0526 Acc: 0.9819, val Loss: 0.1790 Acc: 0.9482\n",
            "Epoch 18/25: train Loss: 0.0526 Acc: 0.9815, val Loss: 0.1757 Acc: 0.9487\n",
            "Epoch 19/25: train Loss: 0.0517 Acc: 0.9818, val Loss: 0.1796 Acc: 0.9462\n",
            "Epoch 20/25: train Loss: 0.0519 Acc: 0.9815, val Loss: 0.1785 Acc: 0.9478\n",
            "Epoch 21/25: train Loss: 0.0509 Acc: 0.9821, val Loss: 0.1794 Acc: 0.9476\n",
            "Epoch 22/25: train Loss: 0.0511 Acc: 0.9819, val Loss: 0.1815 Acc: 0.9479\n",
            "Epoch 23/25: train Loss: 0.0514 Acc: 0.9814, val Loss: 0.1801 Acc: 0.9487\n",
            "Epoch 24/25: train Loss: 0.0515 Acc: 0.9821, val Loss: 0.1780 Acc: 0.9471\n",
            "Epoch 25/25: train Loss: 0.0520 Acc: 0.9818, val Loss: 0.1807 Acc: 0.9473\n",
            "\n",
            "Training complete in 353m 53s\n",
            "Best val Acc: 0.9487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRDtX8IyIOEr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPzSJFj4R9Vt"
      },
      "source": [
        "from fastai.vision import ImageDataBunch, Learner\n",
        "from fastai.callbacks import OneCycleScheduler\n",
        "from fastai.metrics import accuracy\n",
        "\n",
        "dataset = ImageDataBunch.create(trainset, testset)\n",
        "model = copy.deepcopy(ResNext50_model)\n",
        "\n",
        "learn = Learner(dataset, model, opt_func = optim.SGD, loss_func = criterion, metrics = accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSU-NU8nR9AL",
        "outputId": "e55c9802-e814-4c4c-eb5f-b3914e62a1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "learn.lr_find(start_lr = 1e-08, end_lr = 1e-05)\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJKjcn/D/jNnAwnaRuoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQthNr_Kgzgv",
        "outputId": "8fada3fb-9765-4136-9047-a13d467e0801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "cb = OneCycleScheduler(learn, lr_max = 1e-03)\n",
        "\n",
        "learn.fit(5, callbacks = cb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/25 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='937', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-af22735680f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneCycleScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iter_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mupdate_bar\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your generator is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100% [0/0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{100 * val/self.total:.2f}% [{val}/{self.total} {elapsed_t}<{remaining_t}{end}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mon_update\u001b[0;34m(self, val, text, interrupted)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNBMasterBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterBar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mto_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_show\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0madditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate_display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mupdate_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate_display\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"update_display() missing 1 required keyword-only argument: 'display_id'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;31m# kwarg-specified metadata gets precedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0m_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisplayHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, data, metadata, source, transient, update)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         self.session.send(\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         )\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         real_message = [self.pack(msg['header']),\n\u001b[0;32m--> 636\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                         \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    105\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/utils/jsonapi.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'separators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DkBp2wpje9l"
      },
      "source": [
        "Top 3:\n",
        "* ResNext50: 94.87%\n",
        "* DenseNet161: 94.74%\n",
        "* VGG16: 94.56%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGox8ucEi9GO"
      },
      "source": [
        "class RandomErasing(object):\n",
        "    \"\"\"\n",
        "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al.\n",
        "    -------------------------------------------------------------------------------------\n",
        "    probability: The probability that the operation will be performed.\n",
        "    sl: min erasing area\n",
        "    sh: max erasing area\n",
        "    r1: min aspect ratio\n",
        "    mean: erasing value\n",
        "    -------------------------------------------------------------------------------------\n",
        "    \"\"\"\n",
        "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean = [0.4914, 0.4822, 0.4465]):\n",
        "        self.probability = probability\n",
        "        self.mean = mean\n",
        "        self.sl = sl\n",
        "        self.sh = sh\n",
        "        self.r1 = r1\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.uniform(0, 1) > self.probability:\n",
        "            return img\n",
        "\n",
        "        for attempt in range(100):\n",
        "            area = img.size()[1] * img.size()[2]\n",
        "            target_area = random.uniform(self.sl, self.sh) * area\n",
        "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
        "\n",
        "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
        "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
        "\n",
        "            if w < img.size()[2] and h < img.size()[1]:\n",
        "                x1 = random.randint(0, img.size()[1] - h)\n",
        "                y1 = random.randint(0, img.size()[2] - w)\n",
        "                if img.size()[0] == 3:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
        "                else:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                return img\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwZpK6KCi9CX"
      },
      "source": [
        "# taking the mean and std values from ImageNet training for normalization\n",
        "mean_values = [0.3297, 0.3819, 0.3637]\n",
        "std_values = [0.1816, 0.1887, 0.1877]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_values, std_values),\n",
        "    RandomErasing(probability = 0.5, sl = 0.01, sh = 0.2)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_values, std_values)\n",
        "])\n",
        "\n",
        "trainset = FashionMNIST(root = './data', train = True, download = True, transform = train_transform)\n",
        "trainloader = DataLoader(trainset, batch_size = 32, shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = FashionMNIST(root = './data', train = False, download = True, transform = test_transform)\n",
        "testloader = DataLoader(testset, batch_size = 32, shuffle = False, num_workers = 2)\n",
        "\n",
        "dataloaders = {'train': trainloader,\n",
        "               'val'  : testloader}\n",
        "dataset_sizes = {'train': len(trainset),\n",
        "                 'val'  : len(testset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1PT10Q5i8-Q",
        "outputId": "0c868f7e-6977-4751-9e20-e4d6460e971f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "ResNext50 = models.resnext50_32x4d(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(ResNext50.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "ResNext50_model = train_model(ResNext50, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d3044afa5669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mResNext50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNext50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-8ca6a6458353>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T41LiSCkLTv",
        "outputId": "d7d26ac8-e11b-4783-95cd-69f153ccc99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "denseNet161 = models.densenet161(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(denseNet161.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "denseNet161_model = train_model(denseNet161, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-09351e23d2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdenseNet161\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensenet161\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Observe that all parameters are being optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenseNet161\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQ7NAfQkK9g"
      },
      "source": [
        "VGG16 = models.vgg16(pretrained = True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(VGG16.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
        "\n",
        "# Train the model\n",
        "VGG16_model = train_model(VGG16, criterion, optimizer, exp_lr_scheduler, num_epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z905ASbli80s"
      },
      "source": [
        "torch.save(ResNext50_model.state_dict(), 'drive/app/ResNext50RE_Img128.pth')\n",
        "#torch.save(denseNet161_model.state_dict(), 'drive/app/DenseNet161RE_Img128.pth')\n",
        "#torch.save(VGG16_model.state_dict(), 'drive/app/VGG16RE_Img128.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgOOo6pW-6Hf"
      },
      "source": [
        "## Inception\n",
        "See [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567).\n",
        "\n",
        "$\\textbf{Important}$: In contrast to the other models the inception v3 expects tensors with a size of N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
        "\n",
        "This is a problem because our dataset has 28 x 28 sized images. This means we will be sacrificing a lot of quality in the data. But let's try it anyway just to see how it performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4B9bKuF-5-r"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQZYb16-8X1"
      },
      "source": [
        "## GoogLeNet\n",
        "See [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg_fkNwn-Kqr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rruVZxK7RETn"
      },
      "source": [
        "## ShuffleNet\n",
        "See [ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/abs/1807.11164)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFex5QZREuv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IwbDqV3t0Up"
      },
      "source": [
        "## WideResNet\n",
        "See [Wide Residual Networks](https://arxiv.org/abs/1605.07146)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpetPmez2yjg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}